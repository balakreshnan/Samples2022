{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create AML Labeled Tabular Dataset with JSONLine files\n",
        "\n",
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License.\n",
        "\n",
        "version 0.5\n",
        "\n",
        "## Description\n",
        "\n",
        "- This sample notebook shows how to upload and register JSON Line files as an Azure Machine Learning (AML) Tabular Dataset.\n",
        "\n",
        "## Setup\n",
        "\n",
        "To use this notebook, you will need to install following package.\n",
        "\n",
        "```pip install --upgrade \"azureml-core\", \"jsonlines\"```\n",
        "\n",
        "Note: You might need to restart the notebook kernel after installing the packages from within the notebook with the line above, for the packages to be available to use.\n",
        "\n",
        "## Usage\n",
        "\n",
        "- Download and copy config.json from AML workspace to current directory\n",
        "- Specify input parameters in the first cell below\n",
        "- Run all the cells\n",
        "\n",
        "## Parameters\n",
        "\n",
        "| Name | Description | Example |\n",
        "| --- | --- | --- |\n",
        "| task_type | The type of annotation:<br><br>Image Classification Multi-class: 'IMAGE_CLASSIFICATION'<br>Image Classification Multi-label: 'IMAGE_MULTI_LABEL_CLASSIFICATION'<br>Object Identification (Bounding Box): 'OBJECT_DETECTION'<br>Instance Segmentation (Polygon): 'IMAGE_INSTANCE_SEGMENTATION'<br><br>Text Classification Multi-class: 'TEXT_CLASSIFICATION'<br>Text Classification Multi-label: 'TEXT_MULTI_LABEL_CLASSIFICATION'<br>Text Named Entity Recognition: 'TEXT_NAMED_ENTITY_RECOGNITION'| 'IMAGE_INSTANCE_SEGMENTATION' |\n",
        "| dataset_name | The name of the new dataset  | 'MyDataset' |\n",
        "| jsonline_files_path | The name of directory which contains the JSON Line files| 'JsonLines' |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "task_type = 'IMAGE_INSTANCE_SEGMENTATION'\n",
        "dataset_name = 'MyDataset'\n",
        "jsonline_files_path = os.path.join(os.getcwd(), 'JsonLines')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Define DatasetTagsGenerator Class for creating tags from JSONL file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1630689944040
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import jsonlines\n",
        "import pathlib\n",
        "\n",
        "TAG_CREATED_BY = 'labelingCreatedBy'\n",
        "TAG_PROJECT_TYPE = 'labelingProjectType'\n",
        "TAG_SOURCE_DATASTORE_NAME = 'SourceDatastoreName'\n",
        "TAG_SOURCE_RELATIVE_PATH = 'SourceRelativePath'\n",
        "TAG_LABEL_NAME = 'labelingLabelName'\n",
        "\n",
        "Labeling_Project_Type = {\n",
        "    'IMAGE_CLASSIFICATION': 'Image Classification Multi-class',\n",
        "    'IMAGE_MULTI_LABEL_CLASSIFICATION': 'Image Classification',\n",
        "    'OBJECT_DETECTION': 'Object Identification (Bounding Box)',\n",
        "    'IMAGE_INSTANCE_SEGMENTATION': 'Instance Segmentation',\n",
        "    'TEXT_CLASSIFICATION': 'Text Classification Multi-class',\n",
        "    'TEXT_MULTI_LABEL_CLASSIFICATION': 'Text Classification Multi-label',\n",
        "    'TEXT_NAMED_ENTITY_RECOGNITION': 'Text Named Entity Recognition'\n",
        "    }\n",
        " \n",
        "URL_SCHEME = 'AmlDatastore:/'\n",
        "URL_KEY = 'image_url'\n",
        "LABEL_KEY = 'label'\n",
        "\n",
        "\n",
        "class DatasetTagsGenerator:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.labelSet = set()\n",
        "        self.tags = {TAG_CREATED_BY: 'Labeled Dataset Registration NoteBook (v.4)',\n",
        "                     TAG_PROJECT_TYPE: None,\n",
        "                     TAG_SOURCE_DATASTORE_NAME: None,\n",
        "                     TAG_SOURCE_RELATIVE_PATH: None,\n",
        "                     TAG_LABEL_NAME: []}\n",
        "\n",
        "    def get_tags_from_jsonl_files(self, jsonl_file_folder: str, task_type: str) -> dict():\n",
        "        if not os.path.exists(jsonl_file_folder):\n",
        "            raise Exception(\"JsonLine folder {} not found.\".format(jsonl_file_folder))\n",
        "\n",
        "        for root, _, files in os.walk(jsonl_file_folder):\n",
        "            for file in files:\n",
        "                if pathlib.PurePath(file).suffix == '.jsonl':\n",
        "                    with jsonlines.open(os.path.join(root, file)) as reader:\n",
        "                        for json_line in reader:\n",
        "                            self._populate_label_names(json_line)\n",
        "                            self._populate_source_relative_path(json_line[URL_KEY])\n",
        "\n",
        "        p = pathlib.PurePath(self.tags[TAG_SOURCE_RELATIVE_PATH])\n",
        "        p = p.relative_to(URL_SCHEME)\n",
        "\n",
        "        self.tags[TAG_PROJECT_TYPE] = Labeling_Project_Type[task_type]\n",
        "        self.tags[TAG_SOURCE_DATASTORE_NAME] = p.parts[0]\n",
        "        self.tags[TAG_SOURCE_RELATIVE_PATH] = str(pathlib.PurePosixPath(*list(p.parts[1:]))) + \"/**\"\n",
        "        self.tags[TAG_LABEL_NAME] = list(self.labelSet)\n",
        "        return self.tags\n",
        "\n",
        "    def _populate_label_names(self, json_line:str):\n",
        "\n",
        "        if type(json_line[LABEL_KEY]) is list:\n",
        "            for label in json_line[LABEL_KEY]:\n",
        "                if type(label) is dict:\n",
        "                    self.labelSet.add(label[LABEL_KEY])\n",
        "                else:\n",
        "                    self.labelSet.add(label)\n",
        "        else:\n",
        "            self.labelSet.add(json_line[LABEL_KEY])\n",
        "\n",
        "    def _populate_source_relative_path(self, image_url:str):\n",
        "        if self.tags[TAG_SOURCE_RELATIVE_PATH] is None:\n",
        "            self.tags[TAG_SOURCE_RELATIVE_PATH] = image_url\n",
        "        else:\n",
        "            self.tags[TAG_SOURCE_RELATIVE_PATH] = os.path.commonpath([self.tags[TAG_SOURCE_RELATIVE_PATH], image_url])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Initialize Workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1630689638665
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace\n",
        "ws = Workspace.from_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Upload output JSONLines file from the ouput folder to the default Datastore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1630689643522
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def_blob_store = ws.get_default_datastore()\n",
        "path_on_datastore = pathlib.PurePosixPath('/','Labeling', 'datasets', dataset_name)\n",
        "jsonline_files = [os.path.join(jsonline_files_path, file) for _, _, files in os.walk(jsonline_files_path) for file in files if pathlib.PurePath(file).suffix == '.jsonl']\n",
        "dataset_source = def_blob_store.upload_files(jsonline_files, target_path = str(path_on_datastore), overwrite = True, show_progress = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Convert JSONLines to Tabular Dataset and Register the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1630689973237
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory, DataType\n",
        "dataset_list = [k for k in ws.datasets.keys()]\n",
        "if dataset_name in dataset_list:\n",
        "    ouput_labeled_dataset = ws.datasets.get(dataset_name)\n",
        "    print('Dataset \"{}\" has been registered in workspace \"{}\", please provide a different dataset name.'.format(dataset_name, ws.name))\n",
        "else:\n",
        "    tagsGenerator = DatasetTagsGenerator()\n",
        "    tags = tagsGenerator.get_tags_from_jsonl_files(jsonline_files_path, task_type)\n",
        "    output_tabular_dataset = TabularDatasetFactory.from_json_lines_files(path = dataset_source, set_column_types = {'image_url': DataType.to_stream(ws)} )\n",
        "    output_tabular_dataset = output_tabular_dataset.register(workspace = ws, name = dataset_name, tags = tags)\n",
        "\n",
        "print('Done.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## End of notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "62a5a7a49ad21bd9631a25bbabef05666b606ab2a71d5c985812dda29a1b1f1c"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('azure_py38': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
